{"train_start": "2015-03-17 00:00:00", "train_end": "2016-02-13 07:00:00", "train_window": 8000, "lambda": 0.2061376928540778, "model": {"n_steps_in": 24, "n_steps_out": 6, "batch_size": 12, "is_stateful": false, "epochs": 1000, "dropout": 0.1, "recurrent_dropout": 0.1, "units_coef": 3, "patience_coef": 0.1, "test_size": 24, "validation_size": 24, "model_name": "simple"}, "results": [{"step_number": 0, "accuracy": {"mse": "3.465", "rmse": "1.861", "mape": "9.450", "mae": "1.527"}, "each_sample_accuracy": [1.183, 3.711, 0.344, 1.029, 1.093, 1.802]}, {"step_number": 1, "accuracy": {"mse": "22.512", "rmse": "4.745", "mape": "19.739", "mae": "3.619"}, "each_sample_accuracy": [3.536, 2.655, 0.632, 1.734, 3.006, 10.153]}, {"step_number": 2, "accuracy": {"mse": "23.141", "rmse": "4.811", "mape": "15.345", "mae": "3.194"}, "each_sample_accuracy": [0.063, 0.292, 0.922, 1.516, 9.071, 7.302]}, {"step_number": 3, "accuracy": {"mse": "34.939", "rmse": "5.911", "mape": "22.226", "mae": "4.379"}, "each_sample_accuracy": [1.246, 1.62, 2.25, 10.803, 9.055, 1.297]}, {"step_number": 4, "accuracy": {"mse": "37.799", "rmse": "6.148", "mape": "23.800", "mae": "4.817"}, "each_sample_accuracy": [1.296, 2.929, 10.238, 9.787, 0.727, 3.925]}, {"step_number": 5, "accuracy": {"mse": "237.813", "rmse": "15.421", "mape": "31.434", "mae": "10.144"}, "each_sample_accuracy": [2.324, 10.326, 9.004, 0.326, 3.988, 34.897]}, {"step_number": 6, "accuracy": {"mse": "386.351", "rmse": "19.656", "mape": "37.362", "mae": "14.548"}, "each_sample_accuracy": [8.445, 7.53, 2.475, 2.877, 33.395, 32.564]}, {"step_number": 7, "accuracy": {"mse": "228.193", "rmse": "15.106", "mape": "40.836", "mae": "13.195"}, "each_sample_accuracy": [1.921, 12.26, 8.08, 22.959, 21.792, 12.159]}, {"step_number": 8, "accuracy": {"mse": "398.525", "rmse": "19.963", "mape": "42.801", "mae": "17.850"}, "each_sample_accuracy": [8.907, 3.75, 27.349, 26.314, 16.798, 23.983]}, {"step_number": 9, "accuracy": {"mse": "1067.337", "rmse": "32.670", "mape": "58.889", "mae": "30.644"}, "each_sample_accuracy": [6.341, 38.448, 38.79, 29.584, 37.132, 33.569]}, {"step_number": 10, "accuracy": {"mse": "690.951", "rmse": "26.286", "mape": "46.613", "mae": "26.057"}, "each_sample_accuracy": [30.223, 28.95, 19.927, 28.084, 24.298, 24.86]}, {"step_number": 11, "accuracy": {"mse": "248.221", "rmse": "15.755", "mape": "28.774", "mae": "14.747"}, "each_sample_accuracy": [7.043, 20.581, 13.954, 13.394, 10.407, 23.103]}, {"step_number": 12, "accuracy": {"mse": "65.593", "rmse": "8.099", "mape": "12.445", "mae": "6.935"}, "each_sample_accuracy": [2.846, 12.374, 9.286, 11.251, 4.02, 1.831]}, {"step_number": 13, "accuracy": {"mse": "179.418", "rmse": "13.395", "mape": "20.878", "mae": "11.357"}, "each_sample_accuracy": [19.083, 17.301, 18.518, 1.842, 6.639, 4.76]}, {"step_number": 14, "accuracy": {"mse": "148.361", "rmse": "12.180", "mape": "31.983", "mae": "10.526"}, "each_sample_accuracy": [8.018, 8.607, 8.475, 2.166, 13.989, 21.899]}, {"step_number": 15, "accuracy": {"mse": "124.711", "rmse": "11.167", "mape": "29.860", "mae": "9.465"}, "each_sample_accuracy": [16.222, 1.137, 3.735, 7.797, 17.104, 10.794]}, {"step_number": 16, "accuracy": {"mse": "120.663", "rmse": "10.985", "mape": "34.524", "mae": "9.250"}, "each_sample_accuracy": [2.279, 2.252, 9.344, 18.546, 14.382, 8.696]}, {"step_number": 17, "accuracy": {"mse": "56.770", "rmse": "7.535", "mape": "14.582", "mae": "4.997"}, "each_sample_accuracy": [16.664, 3.657, 6.694, 2.077, 0.573, 0.318]}, {"step_number": 18, "accuracy": {"mse": "61.931", "rmse": "7.870", "mape": "27.465", "mae": "6.930"}, "each_sample_accuracy": [3.279, 13.998, 9.383, 4.633, 6.259, 4.026]}, {"step_number": 19, "accuracy": {"mse": "26.461", "rmse": "5.144", "mape": "15.093", "mae": "4.189"}, "each_sample_accuracy": [2.396, 1.339, 4.165, 3.416, 3.25, 10.567]}, {"step_number": 20, "accuracy": {"mse": "132.536", "rmse": "11.512", "mape": "40.321", "mae": "11.206"}, "each_sample_accuracy": [8.312, 11.471, 8.633, 9.588, 15.235, 13.999]}, {"step_number": 21, "accuracy": {"mse": "62.544", "rmse": "7.908", "mape": "26.555", "mae": "7.105"}, "each_sample_accuracy": [6.831, 5.822, 4.387, 12.165, 11.034, 2.392]}, {"step_number": 22, "accuracy": {"mse": "33.826", "rmse": "5.816", "mape": "25.301", "mae": "5.337"}, "each_sample_accuracy": [2.377, 3.991, 8.074, 8.783, 3.966, 4.829]}, {"step_number": 23, "accuracy": {"mse": "41.957", "rmse": "6.477", "mape": "23.179", "mae": "5.234"}, "each_sample_accuracy": [4.235, 12.093, 8.09, 3.199, 3.428, 0.36]}], "time": 780.9278719425201}