{"train_start": "2015-02-03 08:00:00", "train_end": "2016-01-02 15:00:00", "train_window": 8000, "lambda": 0.2061376928540778, "model": {"n_steps_in": 24, "n_steps_out": 6, "batch_size": 12, "is_stateful": false, "epochs": 1000, "dropout": 0.1, "recurrent_dropout": 0.1, "units_coef": 3, "patience_coef": 0.1, "test_size": 24, "validation_size": 24, "model_name": "simple"}, "results": [{"step_number": 0, "accuracy": {"mse": "750.066", "rmse": "27.387", "mape": "23.000", "mae": "22.597"}, "each_sample_accuracy": [3.298, 4.025, 15.664, 36.601, 38.647, 37.346]}, {"step_number": 1, "accuracy": {"mse": "817.563", "rmse": "28.593", "mape": "26.957", "mae": "26.557"}, "each_sample_accuracy": [9.945, 13.44, 33.042, 32.908, 35.58, 34.427]}, {"step_number": 2, "accuracy": {"mse": "1121.762", "rmse": "33.493", "mape": "31.273", "mae": "32.387"}, "each_sample_accuracy": [13.411, 37.568, 35.347, 35.253, 37.247, 35.494]}, {"step_number": 3, "accuracy": {"mse": "456.117", "rmse": "21.357", "mape": "20.057", "mae": "21.234"}, "each_sample_accuracy": [19.583, 20.771, 19.028, 19.282, 24.707, 24.031]}, {"step_number": 4, "accuracy": {"mse": "109.637", "rmse": "10.471", "mape": "9.310", "mae": "9.918"}, "each_sample_accuracy": [7.154, 8.631, 6.789, 7.772, 15.033, 14.13]}, {"step_number": 5, "accuracy": {"mse": "117.347", "rmse": "10.833", "mape": "9.480", "mae": "10.065"}, "each_sample_accuracy": [8.745, 12.234, 9.563, 10.565, 16.31, 2.972]}, {"step_number": 6, "accuracy": {"mse": "81.970", "rmse": "9.054", "mape": "7.910", "mae": "8.329"}, "each_sample_accuracy": [8.891, 12.925, 9.967, 10.602, 5.404, 2.186]}, {"step_number": 7, "accuracy": {"mse": "67.813", "rmse": "8.235", "mape": "6.532", "mae": "6.851"}, "each_sample_accuracy": [9.267, 13.325, 10.226, 0.15, 5.763, 2.375]}, {"step_number": 8, "accuracy": {"mse": "132.085", "rmse": "11.493", "mape": "9.082", "mae": "9.373"}, "each_sample_accuracy": [15.193, 20.505, 6.99, 7.416, 6.114, 0.022]}, {"step_number": 9, "accuracy": {"mse": "97.904", "rmse": "9.895", "mape": "9.065", "mae": "8.911"}, "each_sample_accuracy": [16.724, 11.814, 9.325, 5.317, 5.162, 5.128]}, {"step_number": 10, "accuracy": {"mse": "55.746", "rmse": "7.466", "mape": "6.732", "mae": "6.509"}, "each_sample_accuracy": [6.143, 12.584, 5.98, 3.287, 1.613, 9.445]}, {"step_number": 11, "accuracy": {"mse": "196.848", "rmse": "14.030", "mape": "12.913", "mae": "12.735"}, "each_sample_accuracy": [12.293, 14.959, 9.669, 2.029, 16.865, 20.595]}, {"step_number": 12, "accuracy": {"mse": "166.587", "rmse": "12.907", "mape": "11.276", "mae": "11.175"}, "each_sample_accuracy": [7.379, 11.045, 1.37, 14.38, 22.52, 10.357]}, {"step_number": 13, "accuracy": {"mse": "240.642", "rmse": "15.513", "mape": "15.939", "mae": "14.269"}, "each_sample_accuracy": [7.011, 5.885, 17.058, 22.865, 14.34, 18.457]}, {"step_number": 14, "accuracy": {"mse": "455.463", "rmse": "21.342", "mape": "26.020", "mae": "18.466"}, "each_sample_accuracy": [0.855, 20.372, 24.379, 13.801, 15.403, 35.985]}, {"step_number": 15, "accuracy": {"mse": "636.710", "rmse": "25.233", "mape": "36.145", "mae": "24.035"}, "each_sample_accuracy": [18.611, 30.844, 18.38, 12.882, 30.541, 32.955]}, {"step_number": 16, "accuracy": {"mse": "926.510", "rmse": "30.439", "mape": "50.934", "mae": "27.943"}, "each_sample_accuracy": [16.308, 11.1, 21.46, 40.522, 37.696, 40.575]}, {"step_number": 17, "accuracy": {"mse": "1297.602", "rmse": "36.022", "mape": "65.152", "mae": "32.689"}, "each_sample_accuracy": [3.222, 22.327, 42.997, 43.28, 41.48, 42.828]}, {"step_number": 18, "accuracy": {"mse": "1165.479", "rmse": "34.139", "mape": "66.785", "mae": "33.664"}, "each_sample_accuracy": [21.421, 34.002, 36.901, 38.55, 36.497, 34.614]}, {"step_number": 19, "accuracy": {"mse": "374.954", "rmse": "19.364", "mape": "38.707", "mae": "19.238"}, "each_sample_accuracy": [21.569, 15.298, 20.031, 20.508, 17.319, 20.705]}, {"step_number": 20, "accuracy": {"mse": "67.489", "rmse": "8.215", "mape": "15.764", "mae": "7.978"}, "each_sample_accuracy": [9.778, 6.057, 8.643, 5.504, 6.987, 10.901]}, {"step_number": 21, "accuracy": {"mse": "68.433", "rmse": "8.272", "mape": "15.724", "mae": "8.033"}, "each_sample_accuracy": [11.23, 7.809, 5.565, 6.583, 7.001, 10.01]}, {"step_number": 22, "accuracy": {"mse": "53.027", "rmse": "7.282", "mape": "13.148", "mae": "6.795"}, "each_sample_accuracy": [9.945, 3.253, 4.878, 6.063, 6.105, 10.528]}, {"step_number": 23, "accuracy": {"mse": "144.778", "rmse": "12.032", "mape": "21.549", "mae": "9.572"}, "each_sample_accuracy": [6.118, 4.044, 6.001, 7.064, 8.618, 25.587]}], "time": 719.1683402061462}